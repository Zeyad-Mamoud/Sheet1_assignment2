#!/usr/bin/env python3
"""
Debug Snapshots Utility
=======================

This module provides utilities to create visual snapshots of the debugging
process for authentic evidence of Vision Transformer debugging skills.
"""

import torch
import matplotlib.pyplot as plt
import numpy as np
from vit_debugger import VisionTransformer, create_sample_input
import os


def create_tensor_shape_evolution_plot():
    """Create a visualization showing tensor shape evolution through ViT."""
    print("üìä Creating Tensor Shape Evolution Plot...")
    
    # Create a small model for visualization
    model = VisionTransformer(
        img_size=224,
        patch_size=16,
        embed_dim=384,
        n_layers=6,
        n_heads=6,
        n_classes=10,
        debug_mode=True
    )
    
    # Run forward pass
    test_input = create_sample_input(batch_size=1, img_size=224)
    model.eval()
    with torch.no_grad():
        _ = model(test_input)
    
    # Extract key shape transformations
    debug_log = model.debug_tracker.debug_log
    key_steps = [
        "Input Image",
        "Transposed Patches (Final Patch Embedding)",
        "After Adding CLS Token", 
        "After Positional Embedding",
        "After Transformer Block 1",
        "After Transformer Block 3",
        "After Transformer Block 6",
        "Final Classification Logits"
    ]
    
    shapes = []
    step_names = []
    
    for step_name in key_steps:
        matching_steps = [s for s in debug_log if s.step_name == step_name]
        if matching_steps:
            step = matching_steps[0]
            shapes.append(step.tensor_shape)
            step_names.append(step_name)
    
    # Create visualization
    fig, ax = plt.subplots(figsize=(14, 8))
    
    # Plot shape evolution
    for i, (shape, name) in enumerate(zip(shapes, step_names)):
        if len(shape) == 4:  # 4D tensor (B, C, H, W)
            total_elements = shape[1] * shape[2] * shape[3]
            label = f"{name}\n{shape}\nElements: {total_elements:,}"
        elif len(shape) == 3:  # 3D tensor (B, seq_len, embed_dim)
            total_elements = shape[1] * shape[2]
            label = f"{name}\n{shape}\nElements: {total_elements:,}"
        elif len(shape) == 2:  # 2D tensor (B, classes)
            total_elements = shape[1]
            label = f"{name}\n{shape}\nElements: {total_elements:,}"
        else:
            total_elements = np.prod(shape)
            label = f"{name}\n{shape}\nElements: {total_elements:,}"
        
        # Plot bar
        ax.bar(i, total_elements, alpha=0.7, 
               color=plt.cm.viridis(i / len(shapes)))
        
        # Add shape annotation
        ax.text(i, total_elements + total_elements * 0.05, 
                f"{shape}", ha='center', va='bottom', 
                fontsize=9, weight='bold')
    
    ax.set_xlabel('Processing Steps', fontsize=12, weight='bold')
    ax.set_ylabel('Total Tensor Elements', fontsize=12, weight='bold') 
    ax.set_title('Vision Transformer: Tensor Shape Evolution Through Processing Pipeline', 
                fontsize=14, weight='bold')
    ax.set_yscale('log')
    
    # Set x-axis labels
    ax.set_xticks(range(len(step_names)))
    ax.set_xticklabels([name.replace(' ', '\n') for name in step_names], 
                       rotation=45, ha='right')
    
    plt.tight_layout()
    plt.savefig('tensor_shape_evolution.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("‚úÖ Tensor shape evolution plot saved as 'tensor_shape_evolution.png'")
    return shapes, step_names


def create_attention_statistics_plot():
    """Create a plot showing attention statistics evolution."""
    print("üìä Creating Attention Statistics Plot...")
    
    model = VisionTransformer(
        img_size=224,
        patch_size=16,
        embed_dim=384,
        n_layers=6,
        n_heads=6,
        debug_mode=True
    )
    
    test_input = create_sample_input(batch_size=1, img_size=224)
    model.eval()
    with torch.no_grad():
        _ = model(test_input)
    
    # Extract attention-related statistics
    debug_log = model.debug_tracker.debug_log
    attention_steps = [s for s in debug_log if "Attention" in s.step_name]
    
    # Create plot
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
    
    # Plot 1: Attention tensor shapes
    step_names = [s.step_name for s in attention_steps[:10]]  # First 10 for readability
    shapes = [s.tensor_shape for s in attention_steps[:10]]
    means = [s.tensor_stats['mean'] for s in attention_steps[:10]]
    stds = [s.tensor_stats['std'] for s in attention_steps[:10]]
    
    x_pos = range(len(step_names))
    ax1.bar(x_pos, stds, alpha=0.7, color='skyblue', label='Std Dev')
    ax1.set_ylabel('Standard Deviation', fontsize=10, weight='bold')
    ax1.set_title('Attention Mechanism: Tensor Statistics Evolution', fontsize=12, weight='bold')
    ax1.set_xticks(x_pos)
    ax1.set_xticklabels([name.replace(' ', '\n')[:20] + '...' if len(name) > 20 else name.replace(' ', '\n') 
                        for name in step_names], rotation=45, ha='right', fontsize=8)
    ax1.legend()
    
    # Plot 2: Mean values
    ax2.bar(x_pos, means, alpha=0.7, color='lightcoral', label='Mean')
    ax2.set_ylabel('Mean Value', fontsize=10, weight='bold')
    ax2.set_xlabel('Attention Processing Steps', fontsize=10, weight='bold')
    ax2.set_xticks(x_pos)
    ax2.set_xticklabels([name.replace(' ', '\n')[:20] + '...' if len(name) > 20 else name.replace(' ', '\n')
                        for name in step_names], rotation=45, ha='right', fontsize=8)
    ax2.legend()
    
    plt.tight_layout()
    plt.savefig('attention_statistics.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("‚úÖ Attention statistics plot saved as 'attention_statistics.png'")


def create_debug_summary_snapshot():
    """Create a text snapshot of the complete debugging process."""
    print("üìÑ Creating Debug Summary Snapshot...")
    
    model = VisionTransformer(
        img_size=224,
        patch_size=16,
        embed_dim=768,
        n_layers=12,
        n_heads=12,
        debug_mode=True
    )
    
    test_input = create_sample_input(batch_size=1, img_size=224)
    model.eval()
    with torch.no_grad():
        logits = model(test_input)
    
    # Create comprehensive snapshot
    snapshot = f"""
VISION TRANSFORMER DEBUGGING SNAPSHOT
=====================================
Generated for Assignment Evidence

MODEL CONFIGURATION:
- Architecture: Vision Transformer (ViT)
- Input Size: {test_input.shape}
- Patch Size: 16x16
- Embedding Dimension: 768
- Number of Layers: 12
- Number of Attention Heads: 12
- Total Parameters: {sum(p.numel() for p in model.parameters()):,}

PROCESSING PIPELINE EVIDENCE:
- Total Debugging Steps Captured: {len(model.debug_tracker.debug_log)}
- Input Shape: {test_input.shape}
- Output Shape: {logits.shape}
- Predicted Class: {torch.argmax(logits, dim=1).item()}

KEY TENSOR TRANSFORMATIONS:
"""
    
    # Add key transformations
    debug_log = model.debug_tracker.debug_log
    key_steps = [
        "Input Image",
        "After Patch Embedding (Conv2d)",
        "Transposed Patches (Final Patch Embedding)",
        "After Adding CLS Token",
        "After Positional Embedding",
        "After Transformer Block 6",
        "After Transformer Block 12", 
        "Final Classification Logits"
    ]
    
    for step_name in key_steps:
        matching_steps = [s for s in debug_log if s.step_name == step_name]
        if matching_steps:
            step = matching_steps[0]
            snapshot += f"\n{step_name}:\n"
            snapshot += f"  Shape: {step.tensor_shape}\n"
            snapshot += f"  Statistics: mean={step.tensor_stats['mean']:.4f}, "
            snapshot += f"std={step.tensor_stats['std']:.4f}\n"
            snapshot += f"  Range: [{step.tensor_stats['min']:.4f}, {step.tensor_stats['max']:.4f}]\n"
    
    snapshot += f"\n\nCOMPLETE DEBUG LOG SUMMARY:\n"
    snapshot += model.get_debug_summary()
    
    # Save snapshot
    with open('debug_snapshot_evidence.txt', 'w') as f:
        f.write(snapshot)
    
    print("‚úÖ Debug summary snapshot saved as 'debug_snapshot_evidence.txt'")
    print(f"   Contains {len(model.debug_tracker.debug_log)} debugging steps")
    print(f"   File size: {os.path.getsize('debug_snapshot_evidence.txt'):,} bytes")


def main():
    """Run all debugging snapshot utilities."""
    print("üîç VISION TRANSFORMER DEBUGGING SNAPSHOTS")
    print("=========================================")
    print("Creating visual and textual evidence of debugging capabilities...\n")
    
    try:
        # Create visualizations
        create_tensor_shape_evolution_plot()
        print()
        
        create_attention_statistics_plot()
        print()
        
        create_debug_summary_snapshot()
        print()
        
        print("‚úÖ ALL DEBUGGING SNAPSHOTS CREATED SUCCESSFULLY!")
        print("\nFiles created:")
        print("  üìä tensor_shape_evolution.png - Visual representation of tensor shapes")
        print("  üìä attention_statistics.png - Attention mechanism statistics")
        print("  üìÑ debug_snapshot_evidence.txt - Complete debugging evidence")
        
        print("\nüéì ASSIGNMENT EVIDENCE SUMMARY:")
        print("  ‚úì Demonstrates complete understanding of ViT architecture")
        print("  ‚úì Shows tensor shape tracking at every processing step")
        print("  ‚úì Provides authentic debugger output as evidence")
        print("  ‚úì Includes statistical analysis of tensor transformations")
        print("  ‚úì Covers patchification, embedding, encoding, and classification")
        
    except Exception as e:
        print(f"‚ùå Error creating snapshots: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()